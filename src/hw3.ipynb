{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Files \n",
    "\n",
    "### hw3dataset\n",
    "Each row represents a directed edge (link) between nodes separated by a comma.\n",
    "The direction of a edge is from the first node to the second node.\n",
    "```\n",
    "    graph_1.txt: 6 nodes, 5 edges\n",
    "    graph_2.txt: 5 nodes, 5 edges (a circle)\n",
    "    graph_3.txt: 4 nodes, 6 edges\n",
    "    graph_4.txt: 7 nodes, 18 edges (the example in Lecture3, p29)\n",
    "    graph_5.txt: 469 nodes, 1102 edges\n",
    "    graph_6.txt: 1228 nodes, 5220 edges\n",
    "```\n",
    "### Transaction Dataset (in hw1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading ./data/graph_4.txt...\n",
      "reading ./data/graph_5.txt...\n",
      "reading ./data/graph_6.txt...\n",
      "reading ./data/graph_2.txt...\n",
      "reading ./data/.DS_Store...\n",
      "reading ./data/graph_3.txt...\n",
      "reading ./data/graph_1.txt...\n",
      "reading ./data/ibm-5000.txt...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "from collections import defaultdict \n",
    "\n",
    "import numpy as np \n",
    "\n",
    "from easydict import EasyDict as edict\n",
    "from utils import timer \n",
    "# No self loops \n",
    "\n",
    "filedir ='./data/'\n",
    "edges_data = {} \n",
    "for filename in os.listdir(filedir):\n",
    "    edges = [] \n",
    "    filepath = os.path.join(filedir, filename) \n",
    "    print(f'reading {filepath}...')\n",
    "    filesuff = filename.split('.')[0] \n",
    "    if filename.startswith('graph'):\n",
    "        with open(filepath, 'r') as f: \n",
    "            for line in f.readlines():\n",
    "                line = line.strip()\n",
    "                edge = line.split(',')\n",
    "                edges.append(edge)  \n",
    "        edges_data[filesuff] = edges\n",
    "                \n",
    "    elif filename.startswith('ibm'):\n",
    "        with open(filepath, 'r') as f: \n",
    "            for line in f.readlines():\n",
    "                line = line.strip()\n",
    "                edge = line.split()[1:]\n",
    "                edges.append(edge)\n",
    "        edges_data[filesuff] = edges\n",
    "    \n",
    "    \n",
    "    \n",
    "                    \n",
    "\n",
    "class Graph:\n",
    "    def __init__(self, edges):\n",
    "        self.out_neighbors = defaultdict(list)\n",
    "        self.in_neighbors = defaultdict(list)\n",
    "        nodes = set()\n",
    "        for u, v in edges:\n",
    "            nodes.add(u); nodes.add(v) \n",
    "        nodes = sorted(nodes)\n",
    "        print(nodes[:10])    \n",
    "        nodesmap = {node:nodeidx for nodeidx, node in enumerate(nodes)}\n",
    "        for u, v in edges:\n",
    "            u, v = nodesmap[u], nodesmap[v]\n",
    "            self.out_neighbors[u].append(v)\n",
    "            self.in_neighbors[v].append(u)  \n",
    "        self.N = len(nodes)\n",
    "edges_data = sorted(edges_data.items(), key = lambda x:x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', '2', '3', '4', '5', '6']\n",
      "graph_1 : graph with 6 nodes\n",
      "['1', '2', '3', '4', '5']\n",
      "graph_2 : graph with 5 nodes\n",
      "['1', '2', '3', '4']\n",
      "graph_3 : graph with 4 nodes\n",
      "['1', '2', '3', '4', '5', '6', '7']\n",
      "graph_4 : graph with 7 nodes\n",
      "['1', '10', '100', '101', '102', '103', '104', '105', '106', '107']\n",
      "graph_5 : graph with 469 nodes\n",
      "['1', '10', '100', '1000', '1001', '1002', '1003', '1004', '1005', '1006']\n",
      "graph_6 : graph with 1228 nodes\n",
      "['1', '10', '100', '101', '102', '103', '104', '105', '106', '107']\n",
      "ibm-5000 : graph with 836 nodes\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "Graphs = {}\n",
    "for fname, edges in edges_data:\n",
    "    G = Graph(edges)\n",
    "    Graphs[fname] = G\n",
    "    print(fname, f': graph with {G.N} nodes')\n",
    "    # pprint(G.out_neighbors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def nodeid(node:str):\n",
    "    return int(node)-1 \n",
    "\n",
    "def PageRank(G:Graph, \n",
    "            max_iters:int, \n",
    "            damping_factor:float):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        G (networkx.classes.graph.Graph): \n",
    "        max_iters (int): number of iters \n",
    "        damping_factor (float): \n",
    "        The PageRank theory holds that an imaginary surfer who is randomly clicking on links will eventually stop clicking. The probability, at any step, that the person will continue is a damping factor d.\n",
    "    Note that index 0 is null\n",
    "    Note that links from a page to itself are ignored \n",
    "    \"\"\"\n",
    "    N = G.N\n",
    "    if N == 0:\n",
    "        raise ValueError('Empty Graph')\n",
    "    PageRanksHistory = []  \n",
    "    dpfactor = damping_factor\n",
    "    # init \n",
    "    PageRanks = np.full(N, 1/N)\n",
    "    for iter in range(max_iters):\n",
    "        newPageRanks = np.zeros_like(PageRanks)\n",
    "        for i in range(N):\n",
    "            # for every node points to me , update page_rank score as sum of (old_page[ni]) / (ni out links)\n",
    "            for n in G.in_neighbors[i]:\n",
    "                newPageRanks[i] += PageRanks[n] / len(G.out_neighbors[n])\n",
    "        PageRanks = (1-dpfactor) * newPageRanks + dpfactor/N\n",
    "    PageRanks = PageRanks / (PageRanks.sum())\n",
    "    return PageRanks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename, g in Graphs.items():\n",
    "    print(filename)\n",
    "    pageranks = PageRank(g, max_iters=100, damping_factor = 0.15)\n",
    "    print(pageranks)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from typing import Tuple\n",
    "def HITS(G:Graph, \n",
    "    max_iters:int, \n",
    "    denominator = 'sum')-> Tuple[np.array, np.array]:\n",
    "    \"\"\"\n",
    "    HITS(Hyperlink-induced topic search)\n",
    "    Authority: Providing valuable infor on certain topic \n",
    "    Hub: Give good supports to those pages with high authority\n",
    "    - A good hub increases the authority weight of the pages it points. \n",
    "    - A good authority increases the hub weight of the pages that point to it. \n",
    "    The idea is then to apply the two operations above alternatively until equilibrium values for the hub and authority weights are reached.\n",
    "    Args:\n",
    "        G (Graph): _description_\n",
    "    Returns:\n",
    "        Tuple(np.array, np.array): Auth, Hub Vectors \n",
    "            Auth: shape (N, ) Auth[n] is the authority score of node n\n",
    "            Hub: shape (N, )  Similarly, Hub[n] is the hub score of node n\n",
    "    \"\"\"\n",
    "    auths = np.ones(G.N)\n",
    "    hubs = np.ones(G.N)\n",
    "    \n",
    "    def get_update_Auth(n):\n",
    "        # authority: the node being pointed to 越多人指向他越高分\n",
    "        return hubs[G.in_neighbors[n]].sum()\n",
    "    def get_update_Hub(n):\n",
    "        return auths[G.out_neighbors[n]].sum()\n",
    "    \n",
    "    for _ in range(max_iters):\n",
    "        new_auths = np.zeros_like(auths)\n",
    "        new_hubs = np.zeros_like(hubs)\n",
    "        for n in range(G.N):\n",
    "            new_auths[n] = get_update_Auth(n)\n",
    "            new_hubs[n] = get_update_Hub(n)\n",
    "        if denominator == 'sum':\n",
    "            auths = new_auths / np.sum(new_auths)\n",
    "            hubs = new_hubs / np.sum(new_hubs)\n",
    "        else: # root of sum of squares\n",
    "            # 這是wik上上面的正規做法\n",
    "            # https://en.wikipedia.org/wiki/HITS_algorithm\n",
    "            auths = new_auths / np.sqrt(np.sum(new_auths**2))\n",
    "            hubs = new_hubs / np.sqrt(np.sum(new_hubs**2))\n",
    "    \n",
    "    return auths, hubs \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename, g in Graphs.items():\n",
    "    print(filename)\n",
    "    auths, hubs = HITS(g, max_iters=100)\n",
    "    print(list(auths))\n",
    "    print(list(hubs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "@timer \n",
    "def SimRank(G: Graph, \n",
    "            max_iters:int, \n",
    "            decay_factor:float):\n",
    "    # SimRank_sum = the sum of SimRank value of all in-neighbor pairs (SimRank value is from the previous iteration)\n",
    "    C = decay_factor \n",
    "    def get_update_simrank(a:int, b:int, simRank: np.array):\n",
    "        if a == b: \n",
    "            return 1    \n",
    "        a_in_neighbors = G.in_neighbors[a]\n",
    "        b_in_neighbors = G.in_neighbors[b]\n",
    "        a_in_size, b_in_size = len(a_in_neighbors), len(b_in_neighbors)\n",
    "        if not (a_in_size and b_in_size):\n",
    "            return 0\n",
    "        temp = 0 \n",
    "        for ai in a_in_neighbors:\n",
    "            for bi in b_in_neighbors:\n",
    "                temp += simRank[ai, bi]\n",
    "        # scaling the simRank \n",
    "        return C * temp / (a_in_size * b_in_size) \n",
    "                        \n",
    "\n",
    "    simRank = np.zeros((G.N, G.N))\n",
    "    for iter in range(max_iters):\n",
    "        newSimRank = np.zeros_like(simRank)\n",
    "        for a in range(G.N):\n",
    "            for b in range(a, G.N):\n",
    "                newSimRank[a, b] = newSimRank[b, a] = get_update_simrank(a, b, simRank)\n",
    "        simRank = newSimRank \n",
    "    return simRank    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph_1\n",
      "SimRank Done in 0.01 seconds.\n",
      "[[1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]]\n",
      "graph_2\n",
      "SimRank Done in 0.01 seconds.\n",
      "[[1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1.]]\n",
      "graph_3\n",
      "SimRank Done in 0.01 seconds.\n",
      "[[1.         0.         0.81818182 0.        ]\n",
      " [0.         1.         0.         0.81818182]\n",
      " [0.81818182 0.         1.         0.        ]\n",
      " [0.         0.81818182 0.         1.        ]]\n",
      "graph_4\n",
      "SimRank Done in 0.01 seconds.\n",
      "[[1.         0.56308319 0.55339919 0.55602199 0.54405249 0.6027948\n",
      "  0.50924918]\n",
      " [0.56308319 1.         0.59679481 0.56752335 0.60393344 0.50222034\n",
      "  0.63282635]\n",
      " [0.55339919 0.59679481 1.         0.62843716 0.58456124 0.62685197\n",
      "  0.63002234]\n",
      " [0.55602199 0.56752335 0.62843716 1.         0.54545408 0.69482362\n",
      "  0.69482362]\n",
      " [0.54405249 0.60393344 0.58456124 0.54545408 1.         0.49059331\n",
      "  0.60031484]\n",
      " [0.6027948  0.50222034 0.62685197 0.69482362 0.49059331 1.\n",
      "  0.48964724]\n",
      " [0.50924918 0.63282635 0.63002234 0.69482362 0.60031484 0.48964724\n",
      "  1.        ]]\n",
      "graph_5\n",
      "SimRank Done in 29.78 seconds.\n",
      "[[1.     0.     0.     ... 0.     0.     0.    ]\n",
      " [0.     1.     0.     ... 0.     0.     0.    ]\n",
      " [0.     0.     1.     ... 0.     0.     0.    ]\n",
      " ...\n",
      " [0.     0.     0.     ... 1.     0.     0.3645]\n",
      " [0.     0.     0.     ... 0.     1.     0.    ]\n",
      " [0.     0.     0.     ... 0.3645 0.     1.    ]]\n",
      "graph_6\n",
      "Running SimRank ...\r"
     ]
    }
   ],
   "source": [
    "for filename, g in Graphs.items():\n",
    "    print(filename)\n",
    "    simranks = SimRank(g, max_iters=100, decay_factor = 0.9)\n",
    "    print(simranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DM-Project3-SeDdMuxy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "289f25968b238bd00860385a23c5d43f19c30d81fcfa53a367e8ce3e541c3cfb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
